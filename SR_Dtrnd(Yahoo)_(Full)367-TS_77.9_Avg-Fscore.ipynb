{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ம ஹா ம்ரி த் யு ஞ் ஜ யா\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\\nம ஹா ம்ரி த் யு ஞ் ஜ யா\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import tensorflow as tf\n",
    "\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import os\n",
    "from matplotlib import pyplot\n",
    "from pathlib import Path\n",
    "#from tensorflow.contrib.rnn import LSTMCell, GRUCell\n",
    "import numpy as np\n",
    "import time, uuid\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.externals import joblib \n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Box_filter(values, kernel_size=3):\n",
    "    \"\"\"\n",
    "    :return: The list of filtered average\n",
    "    \"\"\"\n",
    "    filter_values = np.cumsum(values, dtype=float)\n",
    "\n",
    "    filter_values[kernel_size:] = filter_values[kernel_size:] - filter_values[:-kernel_size]\n",
    "    filter_values[kernel_size:] = filter_values[kernel_size:] / kernel_size\n",
    "\n",
    "    for i in range(1, kernel_size):\n",
    "        filter_values[i] /= i + 1\n",
    "\n",
    "    return filter_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extrapolate_next(values):\n",
    "    \"\"\"\n",
    "    Extrapolates the next value by sum up the slope of the last value with previous values.\n",
    "    :param values: a list or numpy array of time-series\n",
    "    :return: the next value of time-series\n",
    "    \"\"\"\n",
    "\n",
    "    last_value = values[-1]\n",
    "    slope = [(last_value - v) / i for (i, v) in enumerate(values[::-1])]\n",
    "    slope[0] = 0\n",
    "    next_values = last_value + np.cumsum(slope)\n",
    "\n",
    "    return next_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_series(values, extend_num=5, forward=5):\n",
    "\n",
    "    next_value = extrapolate_next(values)[forward]\n",
    "    extension = [next_value] * extend_num\n",
    "\n",
    "    if isinstance(values, list):\n",
    "        merge_values = values + extension\n",
    "    else:\n",
    "        merge_values = np.append(values, extension)\n",
    "    return merge_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Silency(object):\n",
    "    def __init__(self, amp_window_size, series_window_size, score_window_size):\n",
    "        self.amp_window_size = amp_window_size\n",
    "        self.series_window_size = series_window_size\n",
    "        self.score_window_size = score_window_size\n",
    "\n",
    "    def frequency_domain_map(self, values):\n",
    "        freq = np.fft.fft(values)\n",
    "        mag = np.sqrt(freq.real ** 2 + freq.imag ** 2)\n",
    "        spectral_residual = np.exp(np.log(mag) - Box_filter(np.log(mag), self.amp_window_size))\n",
    "\n",
    "        freq.real = freq.real * spectral_residual / mag\n",
    "        freq.imag = freq.imag * spectral_residual / mag\n",
    "\n",
    "        freqmap = np.fft.ifft(freq)\n",
    "        freq_map = np.sqrt(freqmap.real ** 2 + freqmap.imag ** 2)\n",
    "        return freq_map\n",
    "\n",
    "    def generate_anomaly_score(self, values, type=\"avg\"):\n",
    "        extended_series = merge_series(values, self.series_window_size, self.series_window_size)\n",
    "        mag = self.frequency_domain_map(extended_series)[: len(values)]\n",
    "\n",
    "        ave_filter = Box_filter(mag, self.score_window_size)        \n",
    "        score = (mag - ave_filter) / ave_filter \n",
    "        \n",
    "        return score\n",
    "\n",
    "    def generate_anomaly_score2(self, values, type=\"avg\"):\n",
    "        extended_series = merge_series(values, self.series_window_size, self.series_window_size)\n",
    "        mag = self.frequency_domain_map(extended_series)[: len(values)]\n",
    "\n",
    "        return mag\n",
    "\n",
    "    def generate_anomaly_score_(self, values, type=\"avg\"):\n",
    "        extended_series = merge_series(values, self.series_window_size, self.series_window_size)\n",
    "        mag = self.frequency_domain_map(extended_series)[: len(values)]\n",
    "\n",
    "        ave_filter = Box_filter(mag, self.score_window_size)\n",
    "        \n",
    "        ave_filter1 = Box_filter(ave_filter, 12)\n",
    "        ave_filter2 = Box_filter(ave_filter1, 8)\n",
    "        ave_filter = Box_filter(ave_filter2, 6)\n",
    "        \n",
    "        score = (mag - ave_filter) / ave_filter\n",
    "        \n",
    "        return score\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def box_filter(ts, n) :\n",
    "    ret = np.cumsum(ts, dtype=float)\n",
    "    ret[n:] = ret[n:] - ret[:-n]\n",
    "    ret[n:] = ret[n:] / n\n",
    "\n",
    "    for i in range(1, n):\n",
    "        ret[i] /= i + 1\n",
    "\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entire A4 folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/manjunath.adinarayan/TIME-SERIES/YAHOO_Data/Full_data/'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "extension='csv'\n",
    "os.chdir( path )\n",
    "files = glob.glob('*.{}'.format(extension))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['real_59.csv',\n",
       " 'real_65.csv',\n",
       " 'A3Benchmark-TS12.csv',\n",
       " 'synthetic_85.csv',\n",
       " 'synthetic_91.csv',\n",
       " 'A4Benchmark-TS99.csv',\n",
       " 'A4Benchmark-TS72.csv',\n",
       " 'synthetic_46.csv',\n",
       " 'synthetic_52.csv',\n",
       " 'A4Benchmark-TS66.csv',\n",
       " 'synthetic_53.csv',\n",
       " 'A4Benchmark-TS67.csv',\n",
       " 'A4Benchmark-TS73.csv',\n",
       " 'synthetic_47.csv',\n",
       " 'A4Benchmark-TS98.csv',\n",
       " 'synthetic_90.csv',\n",
       " 'synthetic_84.csv',\n",
       " 'A3Benchmark-TS13.csv',\n",
       " 'real_64.csv',\n",
       " 'real_58.csv',\n",
       " 'real_66.csv',\n",
       " 'A3Benchmark-TS11.csv',\n",
       " 'A3Benchmark-TS39.csv',\n",
       " 'synthetic_92.csv',\n",
       " 'synthetic_86.csv',\n",
       " 'A4Benchmark-TS65.csv',\n",
       " 'synthetic_51.csv',\n",
       " 'synthetic_45.csv',\n",
       " 'A4Benchmark-TS71.csv',\n",
       " 'A4Benchmark-TS59.csv',\n",
       " 'synthetic_79.csv',\n",
       " 'synthetic_78.csv',\n",
       " 'synthetic_100.csv',\n",
       " 'A4Benchmark-TS58.csv',\n",
       " 'synthetic_44.csv',\n",
       " 'A4Benchmark-TS70.csv',\n",
       " 'A4Benchmark-TS64.csv',\n",
       " 'synthetic_50.csv',\n",
       " 'synthetic_87.csv',\n",
       " 'synthetic_93.csv',\n",
       " 'A3Benchmark-TS38.csv',\n",
       " 'A3Benchmark-TS10.csv',\n",
       " 'real_67.csv',\n",
       " 'real_63.csv',\n",
       " 'A3Benchmark-TS28.csv',\n",
       " 'A3Benchmark-TS14.csv',\n",
       " 'synthetic_97.csv',\n",
       " 'synthetic_83.csv',\n",
       " 'synthetic_68.csv',\n",
       " 'A4Benchmark-TS48.csv',\n",
       " 'synthetic_54.csv',\n",
       " 'A4Benchmark-TS60.csv',\n",
       " 'A4Benchmark-TS74.csv',\n",
       " 'synthetic_40.csv',\n",
       " 'A4Benchmark-TS75.csv',\n",
       " 'synthetic_41.csv',\n",
       " 'synthetic_55.csv',\n",
       " 'A4Benchmark-TS61.csv',\n",
       " 'A4Benchmark-TS49.csv',\n",
       " 'synthetic_69.csv',\n",
       " 'synthetic_82.csv',\n",
       " 'synthetic_96.csv',\n",
       " 'A3Benchmark-TS15.csv',\n",
       " 'A3Benchmark-TS29.csv',\n",
       " 'real_62.csv',\n",
       " 'real_60.csv',\n",
       " 'real_48.csv',\n",
       " 'A3Benchmark-TS17.csv',\n",
       " 'A4Benchmark-TS88.csv',\n",
       " 'synthetic_80.csv',\n",
       " 'synthetic_94.csv',\n",
       " 'synthetic_43.csv',\n",
       " 'A4Benchmark-TS77.csv',\n",
       " 'A4Benchmark-TS63.csv',\n",
       " 'synthetic_57.csv',\n",
       " 'A4Benchmark-TS62.csv',\n",
       " 'synthetic_56.csv',\n",
       " 'synthetic_42.csv',\n",
       " 'A4Benchmark-TS76.csv',\n",
       " 'synthetic_95.csv',\n",
       " 'synthetic_81.csv',\n",
       " 'A4Benchmark-TS89.csv',\n",
       " 'A3Benchmark-TS16.csv',\n",
       " 'real_49.csv',\n",
       " 'real_61.csv',\n",
       " 'real_12.csv',\n",
       " 'real_5.csv',\n",
       " 'A3Benchmark-TS65.csv',\n",
       " 'A3Benchmark-TS71.csv',\n",
       " 'A3Benchmark-TS59.csv',\n",
       " 'A3Benchmark-TS5.csv',\n",
       " 'synthetic_25.csv',\n",
       " 'A4Benchmark-TS11.csv',\n",
       " 'synthetic_31.csv',\n",
       " 'synthetic_19.csv',\n",
       " 'A4Benchmark-TS39.csv',\n",
       " 'A4Benchmark-TS38.csv',\n",
       " 'synthetic_18.csv',\n",
       " 'synthetic_30.csv',\n",
       " 'synthetic_24.csv',\n",
       " 'A4Benchmark-TS10.csv',\n",
       " 'A3Benchmark-TS4.csv',\n",
       " 'A3Benchmark-TS58.csv',\n",
       " 'A3Benchmark-TS70.csv',\n",
       " 'A3Benchmark-TS64.csv',\n",
       " 'real_4.csv',\n",
       " 'real_13.csv',\n",
       " 'real_39.csv',\n",
       " 'real_11.csv',\n",
       " 'A4Benchmark-TS8.csv',\n",
       " 'real_6.csv',\n",
       " 'A3Benchmark-TS72.csv',\n",
       " 'A3Benchmark-TS66.csv',\n",
       " 'A3Benchmark-TS6.csv',\n",
       " 'A3Benchmark-TS99.csv',\n",
       " 'synthetic_32.csv',\n",
       " 'A4Benchmark-TS12.csv',\n",
       " 'synthetic_26.csv',\n",
       " 'A4Benchmark-TS13.csv',\n",
       " 'synthetic_27.csv',\n",
       " 'synthetic_33.csv',\n",
       " 'A3Benchmark-TS98.csv',\n",
       " 'A3Benchmark-TS7.csv',\n",
       " 'A3Benchmark-TS67.csv',\n",
       " 'A3Benchmark-TS73.csv',\n",
       " 'real_7.csv',\n",
       " 'A4Benchmark-TS9.csv',\n",
       " 'A4Benchmark-TS100.csv',\n",
       " 'real_10.csv',\n",
       " 'real_38.csv',\n",
       " 'real_14.csv',\n",
       " 'real_28.csv',\n",
       " 'real_3.csv',\n",
       " 'synthetic_8.csv',\n",
       " 'A3Benchmark-TS77.csv',\n",
       " 'A3Benchmark-TS63.csv',\n",
       " 'A3Benchmark-TS88.csv',\n",
       " 'A3Benchmark-TS3.csv',\n",
       " 'synthetic_37.csv',\n",
       " 'synthetic_23.csv',\n",
       " 'A4Benchmark-TS17.csv',\n",
       " 'synthetic_22.csv',\n",
       " 'A4Benchmark-TS16.csv',\n",
       " 'synthetic_36.csv',\n",
       " 'A3Benchmark-TS2.csv',\n",
       " 'A3Benchmark-TS89.csv',\n",
       " 'A3Benchmark-TS62.csv',\n",
       " 'A3Benchmark-TS76.csv',\n",
       " 'synthetic_9.csv',\n",
       " 'real_2.csv',\n",
       " 'real_29.csv',\n",
       " 'real_15.csv',\n",
       " 'real_17.csv',\n",
       " 'A3Benchmark-TS48.csv',\n",
       " 'A3Benchmark-TS60.csv',\n",
       " 'A3Benchmark-TS74.csv',\n",
       " 'A4Benchmark-TS28.csv',\n",
       " 'A4Benchmark-TS14.csv',\n",
       " 'synthetic_20.csv',\n",
       " 'synthetic_34.csv',\n",
       " 'synthetic_35.csv',\n",
       " 'A4Benchmark-TS15.csv',\n",
       " 'synthetic_21.csv',\n",
       " 'A4Benchmark-TS29.csv',\n",
       " 'A3Benchmark-TS1.csv',\n",
       " 'A3Benchmark-TS75.csv',\n",
       " 'A3Benchmark-TS61.csv',\n",
       " 'A3Benchmark-TS49.csv',\n",
       " 'real_1.csv',\n",
       " 'real_16.csv',\n",
       " 'real_33.csv',\n",
       " 'real_27.csv',\n",
       " 'A4Benchmark-TS2.csv',\n",
       " 'synthetic_7.csv',\n",
       " 'A3Benchmark-TS44.csv',\n",
       " 'A3Benchmark-TS50.csv',\n",
       " 'A3Benchmark-TS78.csv',\n",
       " 'A3Benchmark-TS87.csv',\n",
       " 'A3Benchmark-TS93.csv',\n",
       " 'A4Benchmark-TS30.csv',\n",
       " 'A4Benchmark-TS24.csv',\n",
       " 'synthetic_10.csv',\n",
       " 'synthetic_38.csv',\n",
       " 'A4Benchmark-TS18.csv',\n",
       " 'A4Benchmark-TS19.csv',\n",
       " 'synthetic_39.csv',\n",
       " 'A4Benchmark-TS25.csv',\n",
       " 'synthetic_11.csv',\n",
       " 'A4Benchmark-TS31.csv',\n",
       " 'A3Benchmark-TS92.csv',\n",
       " 'A3Benchmark-TS86.csv',\n",
       " 'A3Benchmark-TS79.csv',\n",
       " 'A3Benchmark-TS51.csv',\n",
       " 'A3Benchmark-TS45.csv',\n",
       " 'synthetic_6.csv',\n",
       " 'A4Benchmark-TS3.csv',\n",
       " 'real_26.csv',\n",
       " 'real_32.csv',\n",
       " 'real_18.csv',\n",
       " 'real_24.csv',\n",
       " 'real_30.csv',\n",
       " 'A4Benchmark-TS1.csv',\n",
       " 'synthetic_4.csv',\n",
       " 'A3Benchmark-TS53.csv',\n",
       " 'A3Benchmark-TS47.csv',\n",
       " 'A3Benchmark-TS90.csv',\n",
       " 'A3Benchmark-TS84.csv',\n",
       " 'synthetic_13.csv',\n",
       " 'A4Benchmark-TS27.csv',\n",
       " 'A4Benchmark-TS33.csv',\n",
       " 'A4Benchmark-TS32.csv',\n",
       " 'synthetic_12.csv',\n",
       " 'A4Benchmark-TS26.csv',\n",
       " 'A3Benchmark-TS85.csv',\n",
       " 'A3Benchmark-TS91.csv',\n",
       " 'A3Benchmark-TS46.csv',\n",
       " 'A3Benchmark-TS52.csv',\n",
       " 'synthetic_5.csv',\n",
       " 'real_31.csv',\n",
       " 'real_25.csv',\n",
       " 'real_19.csv',\n",
       " 'real_21.csv',\n",
       " 'real_35.csv',\n",
       " 'A4Benchmark-TS4.csv',\n",
       " 'synthetic_1.csv',\n",
       " 'A3Benchmark-TS56.csv',\n",
       " 'A3Benchmark-TS42.csv',\n",
       " 'A3Benchmark-TS95.csv',\n",
       " 'A3Benchmark-TS81.csv',\n",
       " 'A4Benchmark-TS22.csv',\n",
       " 'synthetic_16.csv',\n",
       " 'A4Benchmark-TS36.csv',\n",
       " 'A4Benchmark-TS37.csv',\n",
       " 'A4Benchmark-TS23.csv',\n",
       " 'synthetic_17.csv',\n",
       " 'A3Benchmark-TS80.csv',\n",
       " 'A3Benchmark-TS94.csv',\n",
       " 'A3Benchmark-TS43.csv',\n",
       " 'A3Benchmark-TS57.csv',\n",
       " 'A4Benchmark-TS5.csv',\n",
       " 'real_34.csv',\n",
       " 'real_20.csv',\n",
       " 'real_36.csv',\n",
       " 'real_22.csv',\n",
       " 'A4Benchmark-TS7.csv',\n",
       " 'real_9.csv',\n",
       " 'synthetic_2.csv',\n",
       " 'A3Benchmark-TS69.csv',\n",
       " 'A3Benchmark-TS41.csv',\n",
       " 'A3Benchmark-TS55.csv',\n",
       " 'A3Benchmark-TS9.csv',\n",
       " 'A3Benchmark-TS82.csv',\n",
       " 'A3Benchmark-TS96.csv',\n",
       " 'synthetic_29.csv',\n",
       " 'A4Benchmark-TS35.csv',\n",
       " 'synthetic_15.csv',\n",
       " 'A4Benchmark-TS21.csv',\n",
       " 'synthetic_14.csv',\n",
       " 'A4Benchmark-TS20.csv',\n",
       " 'A4Benchmark-TS34.csv',\n",
       " 'synthetic_28.csv',\n",
       " 'A3Benchmark-TS97.csv',\n",
       " 'A3Benchmark-TS83.csv',\n",
       " 'A3Benchmark-TS8.csv',\n",
       " 'A3Benchmark-TS54.csv',\n",
       " 'A3Benchmark-TS40.csv',\n",
       " 'A3Benchmark-TS68.csv',\n",
       " 'synthetic_3.csv',\n",
       " 'real_8.csv',\n",
       " 'A4Benchmark-TS6.csv',\n",
       " 'real_23.csv',\n",
       " 'real_37.csv',\n",
       " 'real_50.csv',\n",
       " 'real_44.csv',\n",
       " 'A3Benchmark-TS100.csv',\n",
       " 'A3Benchmark-TS27.csv',\n",
       " 'A3Benchmark-TS33.csv',\n",
       " 'A4Benchmark-TS90.csv',\n",
       " 'A4Benchmark-TS84.csv',\n",
       " 'synthetic_98.csv',\n",
       " 'A4Benchmark-TS53.csv',\n",
       " 'synthetic_67.csv',\n",
       " 'synthetic_73.csv',\n",
       " 'A4Benchmark-TS47.csv',\n",
       " 'synthetic_72.csv',\n",
       " 'A4Benchmark-TS46.csv',\n",
       " 'A4Benchmark-TS52.csv',\n",
       " 'synthetic_66.csv',\n",
       " 'synthetic_99.csv',\n",
       " 'A4Benchmark-TS85.csv',\n",
       " 'A4Benchmark-TS91.csv',\n",
       " 'A3Benchmark-TS32.csv',\n",
       " 'A3Benchmark-TS26.csv',\n",
       " 'real_45.csv',\n",
       " 'real_51.csv',\n",
       " 'real_47.csv',\n",
       " 'real_53.csv',\n",
       " 'A3Benchmark-TS30.csv',\n",
       " 'A3Benchmark-TS24.csv',\n",
       " 'A3Benchmark-TS18.csv',\n",
       " 'A4Benchmark-TS87.csv',\n",
       " 'A4Benchmark-TS93.csv',\n",
       " 'A4Benchmark-TS44.csv',\n",
       " 'synthetic_70.csv',\n",
       " 'synthetic_64.csv',\n",
       " 'A4Benchmark-TS50.csv',\n",
       " 'A4Benchmark-TS78.csv',\n",
       " 'synthetic_58.csv',\n",
       " 'synthetic_59.csv',\n",
       " 'A4Benchmark-TS79.csv',\n",
       " 'synthetic_65.csv',\n",
       " 'A4Benchmark-TS51.csv',\n",
       " 'A4Benchmark-TS45.csv',\n",
       " 'synthetic_71.csv',\n",
       " 'A4Benchmark-TS92.csv',\n",
       " 'A4Benchmark-TS86.csv',\n",
       " 'A3Benchmark-TS19.csv',\n",
       " 'A3Benchmark-TS25.csv',\n",
       " 'A3Benchmark-TS31.csv',\n",
       " 'real_52.csv',\n",
       " 'real_46.csv',\n",
       " 'real_42.csv',\n",
       " 'real_56.csv',\n",
       " 'A3Benchmark-TS35.csv',\n",
       " 'A3Benchmark-TS21.csv',\n",
       " 'A4Benchmark-TS82.csv',\n",
       " 'A4Benchmark-TS96.csv',\n",
       " 'synthetic_49.csv',\n",
       " 'A4Benchmark-TS69.csv',\n",
       " 'synthetic_75.csv',\n",
       " 'A4Benchmark-TS41.csv',\n",
       " 'A4Benchmark-TS55.csv',\n",
       " 'synthetic_61.csv',\n",
       " 'A4Benchmark-TS54.csv',\n",
       " 'synthetic_60.csv',\n",
       " 'synthetic_74.csv',\n",
       " 'A4Benchmark-TS40.csv',\n",
       " 'A4Benchmark-TS68.csv',\n",
       " 'synthetic_48.csv',\n",
       " 'A4Benchmark-TS97.csv',\n",
       " 'A4Benchmark-TS83.csv',\n",
       " 'A3Benchmark-TS20.csv',\n",
       " 'A3Benchmark-TS34.csv',\n",
       " 'real_57.csv',\n",
       " 'real_43.csv',\n",
       " 'real_55.csv',\n",
       " 'real_41.csv',\n",
       " 'A3Benchmark-TS22.csv',\n",
       " 'A3Benchmark-TS36.csv',\n",
       " 'synthetic_89.csv',\n",
       " 'A4Benchmark-TS95.csv',\n",
       " 'A4Benchmark-TS81.csv',\n",
       " 'synthetic_62.csv',\n",
       " 'A4Benchmark-TS56.csv',\n",
       " 'A4Benchmark-TS42.csv',\n",
       " 'synthetic_76.csv',\n",
       " 'A4Benchmark-TS43.csv',\n",
       " 'synthetic_77.csv',\n",
       " 'synthetic_63.csv',\n",
       " 'A4Benchmark-TS57.csv',\n",
       " 'A4Benchmark-TS80.csv',\n",
       " 'A4Benchmark-TS94.csv',\n",
       " 'synthetic_88.csv',\n",
       " 'A3Benchmark-TS37.csv',\n",
       " 'A3Benchmark-TS23.csv',\n",
       " 'real_40.csv',\n",
       " 'real_54.csv']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# less than period\n",
    "amp_window_size=4\n",
    "# (maybe) as same as period\n",
    "series_window_size=4\n",
    "# a number enough larger than period\n",
    "score_window_size=16\n",
    "\n",
    "spec = Silency(amp_window_size, series_window_size, score_window_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "\n",
    "prec_list, rec_list, f1score_list = [], [], []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(os.path.join(path,file), header=0)\n",
    "\n",
    "    test_signal = df.value.values \n",
    "\n",
    "    score = spec.generate_anomaly_score_(test_signal)\n",
    "\n",
    "    index_changes = np.where(score > np.percentile(score, 99))[0]\n",
    "\n",
    "    cutoff = np.percentile(score, 99)\n",
    "\n",
    "    pred_anom = []\n",
    "    for i in range(0, len(score)):\n",
    "        if score[i] > cutoff:\n",
    "            pred_anom.append(1)\n",
    "        else:\n",
    "            pred_anom.append(0)\n",
    "            \n",
    "#    pred_anom = np.zeros(len(test_signal))\n",
    "#    for i in range(int(len(test_signal))):\n",
    "#        for j in index_changes:\n",
    "#            pred_anom[j] = 1\n",
    "\n",
    "    if \"Benchmark\" in file:\n",
    "        prec_list.append(precision_score(df.anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.anomaly.values, pred_anom) )\n",
    "    else:\n",
    "        prec_list.append(precision_score(df.is_anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.is_anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.is_anomaly.values, pred_anom) )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.40723272960410317, 0.8852972149525491, 0.5047092172414838)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(prec_list), np.mean(rec_list), np.mean(f1score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# EXPERIMENTS: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# less than period\n",
    "amp_window_size=3\n",
    "# (maybe) as same as period\n",
    "series_window_size=3\n",
    "# a number enough larger than period\n",
    "score_window_size=32\n",
    "\n",
    "spec = Silency(amp_window_size, series_window_size, score_window_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# fixed threshold '4'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BEST parameter set, F1_score = 74.57%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='/Users/manjunath.adinarayan/TIME-SERIES/YAHOO_Data/A1Benchmark/'\n",
    "path = '/Users/manjunath.adinarayan/TIME-SERIES/YAHOO_Data/Full_data/'\n",
    "\n",
    "extension='csv'\n",
    "os.chdir( path )\n",
    "files = glob.glob('*.{}'.format(extension))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detrending tried only for (FULL DATA) this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "real_59.csv 0.0\n",
      "real_65.csv 0.09523809523809523\n",
      "real_64.csv 0.0\n",
      "real_58.csv 0.04444444444444444\n",
      "real_66.csv 0.25\n",
      "real_67.csv 0.08\n",
      "real_63.csv 0.0\n",
      "real_62.csv 0.6153846153846153\n",
      "real_60.csv 0.3703703703703703\n",
      "real_48.csv 0.0\n",
      "real_49.csv 0.5\n",
      "real_61.csv 0.0\n",
      "real_12.csv 0.5714285714285715\n",
      "real_5.csv 0.28571428571428575\n",
      "real_4.csv 0.4000000000000001\n",
      "real_13.csv 0.5\n",
      "real_39.csv 0.5263157894736842\n",
      "real_11.csv 0.2727272727272727\n",
      "real_6.csv 0.4\n",
      "real_7.csv 0.0\n",
      "real_10.csv 0.0\n",
      "real_38.csv 0.3157894736842105\n",
      "real_14.csv 0.13333333333333336\n",
      "real_28.csv 0.06818181818181818\n",
      "real_3.csv 0.26086956521739135\n",
      "real_2.csv 0.3636363636363636\n",
      "real_29.csv 0.6666666666666666\n",
      "real_15.csv 0.588235294117647\n",
      "real_17.csv 0.04273504273504274\n",
      "real_1.csv 1.0\n",
      "real_16.csv 0.8\n",
      "real_33.csv 0.3333333333333333\n",
      "real_27.csv 0.6666666666666666\n",
      "real_26.csv 0.0\n",
      "real_32.csv 0.21428571428571427\n",
      "real_18.csv 0.5\n",
      "real_24.csv 0.2857142857142857\n",
      "real_30.csv 0.26666666666666666\n",
      "real_31.csv 0.13333333333333333\n",
      "real_25.csv 0.041666666666666664\n",
      "real_19.csv 0.04273504273504274\n",
      "real_21.csv 0.5\n",
      "real_35.csv 0.0\n",
      "real_34.csv 0.5333333333333333\n",
      "real_20.csv 0.2\n",
      "real_36.csv 0.4615384615384615\n",
      "real_22.csv 0.030303030303030304\n",
      "real_9.csv 0.5333333333333333\n",
      "real_8.csv 0.3870967741935483\n",
      "real_23.csv 0.23999999999999996\n",
      "real_37.csv 0.125\n",
      "real_50.csv 0.0\n",
      "real_44.csv 0.4761904761904762\n",
      "real_45.csv 1.0\n",
      "real_51.csv 0.6666666666666666\n",
      "real_47.csv 0.5\n",
      "real_53.csv 0.3636363636363636\n",
      "real_52.csv 0.5555555555555556\n",
      "real_46.csv 0.034782608695652174\n",
      "real_42.csv 0.0\n",
      "real_56.csv 0.6\n",
      "real_57.csv 0.5714285714285715\n",
      "real_43.csv 0.20512820512820512\n",
      "real_55.csv 0.6666666666666665\n",
      "real_41.csv 0.5\n",
      "real_40.csv 0.023255813953488372\n",
      "real_54.csv 1.0\n",
      "Time taken = 0.5714950561523438 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.47181184828243655, 0.3215923447859204, 0.32551326227431154, 67)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = time.time()\n",
    "prec_list, rec_list, f1score_list = [], [], []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(os.path.join(path,file), header=0)\n",
    "    test_sig = df.value.values \n",
    "    \n",
    "    ma = box_filter(test_sig, n=24)\n",
    "    test_signal = test_sig - ma # detrend\n",
    "        \n",
    "    score = spec.generate_anomaly_score(test_signal)\n",
    "    index_changes = np.where(score > np.percentile(score, 99))[0]\n",
    "    cutoff = np.percentile(score, 99)\n",
    "    cutoff = 4\n",
    "    pred_anom = []\n",
    "    for i in range(0, len(score)):\n",
    "        if score[i] > cutoff:\n",
    "            pred_anom.append(1)\n",
    "        else:\n",
    "            pred_anom.append(0)\n",
    "            \n",
    "    if \"Benchmark\" in file:\n",
    "        prec_list.append(precision_score(df.anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.anomaly.values, pred_anom) )\n",
    "        print(file, f1_score(df.anomaly.values, pred_anom))\n",
    "    else:\n",
    "        prec_list.append(precision_score(df.is_anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.is_anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.is_anomaly.values, pred_anom) )\n",
    "        \n",
    "        print(file, f1_score(df.is_anomaly.values, pred_anom))\n",
    "print(\"Time taken =\", (time.time()-st), \"seconds\")\n",
    "np.mean(prec_list), np.mean(rec_list), np.mean(f1score_list), len(f1score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken = 20.755525827407837 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8198337983720256, 0.8005761167654072, 0.7790611637889208, 367)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Time taken =\", (time.time()-st), \"seconds\")\n",
    "np.mean(prec_list), np.mean(rec_list), np.mean(f1score_list), len(f1score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual Fscore of Yahoo's A1, A2, A3, A4\n",
    "#A1 = 32.55%\n",
    "#A2 = 78.09%\n",
    "#A3 = 95.41%\n",
    "#A4 = 90.59%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "77.90149863760217"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(67*(32.55)+7809+9541+9059)/367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ### Detrending tried only for (HALF DATA) this experiment  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path='/Users/manjunath.adinarayan/TIME-SERIES/YAHOO_Data/A4Benchmark/'\n",
    "path = '/Users/manjunath.adinarayan/TIME-SERIES/YAHOO_Data/Full_data/'\n",
    "\n",
    "extension='csv'\n",
    "os.chdir( path )\n",
    "files = glob.glob('*.{}'.format(extension))\n",
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no true samples.\n",
      "  'recall', 'true', average, warn_for)\n",
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n",
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/sklearn/metrics/classification.py:1135: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 due to no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken = 2.5962510108947754 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.8142532762423771, 0.7594252731911294, 0.7512426147356498)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "st = time.time()\n",
    "prec_list, rec_list, f1score_list = [], [], []\n",
    "\n",
    "for file in files:\n",
    "    df1 = pd.read_csv(os.path.join(path,file), header=0)\n",
    "    df = df1.iloc[int(len(df1)/2):, :]\n",
    "    #test_signal = df.value.values \n",
    "    test_sig = df.value.values \n",
    "    \n",
    "    ma = box_filter(test_sig, n=24)\n",
    "    test_signal = test_sig - ma # detrend\n",
    "    \n",
    "    score = spec.generate_anomaly_score(test_signal)\n",
    "    index_changes = np.where(score > np.percentile(score, 99))[0]\n",
    "    cutoff = np.percentile(score, 99)\n",
    "    cutoff = 4\n",
    "    pred_anom = []\n",
    "    for i in range(0, len(score)):\n",
    "        if score[i] > cutoff:\n",
    "            pred_anom.append(1)\n",
    "        else:\n",
    "            pred_anom.append(0)\n",
    "            \n",
    "    if \"Benchmark\" in file:\n",
    "        prec_list.append(precision_score(df.anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.anomaly.values, pred_anom) )\n",
    "    else:\n",
    "        prec_list.append(precision_score(df.is_anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.is_anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.is_anomaly.values, pred_anom) )\n",
    "\n",
    "print(\"Time taken =\", (time.time()-st), \"seconds\")\n",
    "np.mean(prec_list), np.mean(rec_list), np.mean(f1score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(f1score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Individual Fscore of Yahoo's A1, A2, A3, A4\n",
    "#A1 = 29.07%\n",
    "#A2 = 78.65%\n",
    "#A3 = 92.05%\n",
    "#A4 = 85.55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "75.1299455040872"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "((67*29.07)+7865+9205+8555)/367"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced SR with no averaging/filtering of saliency map\n",
    "# and\n",
    "# cutoff = 7 * np.mean(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def generate_anomaly_score(self, values, type=\"avg\"):\n",
    "\n",
    "        extended_series = merge_series(values, self.series_window_size, self.series_window_size)\n",
    "        \n",
    "        mag = self.frequency_domain_map(extended_series)[: len(values)]\n",
    "        \n",
    "        return mag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6509540021083907, 0.7779652423245614, 0.6508797391830556)"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec_list, rec_list, f1score_list = [], [], []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(os.path.join(path,file), header=0)\n",
    "    test_signal = df.value.values \n",
    "    score = spec.generate_anomaly_score2(test_signal)\n",
    "    index_changes = np.where(score > np.percentile(score, 99))[0]\n",
    "    cutoff = np.percentile(score, 99)\n",
    "    cutoff = 7 * np.mean(score)\n",
    "    pred_anom = []\n",
    "    for i in range(0, len(score)):\n",
    "        if score[i] > cutoff:\n",
    "            pred_anom.append(1)\n",
    "        else:\n",
    "            pred_anom.append(0)\n",
    "            \n",
    "    if \"Benchmark\" in file:\n",
    "        prec_list.append(precision_score(df.anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.anomaly.values, pred_anom) )\n",
    "    else:\n",
    "        prec_list.append(precision_score(df.is_anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.is_anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.is_anomaly.values, pred_anom) )\n",
    "\n",
    "np.mean(prec_list), np.mean(rec_list), np.mean(f1score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.675088970218398, 0.7560466291248261, 0.6570270138255867)"
      ]
     },
     "execution_count": 146,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec_list, rec_list, f1score_list = [], [], []\n",
    "\n",
    "for file in files:\n",
    "    df1 = pd.read_csv(os.path.join(path,file), header=0)\n",
    "    df = df1.iloc[int(len(df1)/2):, :]\n",
    "    test_signal = df.value.values \n",
    "    score = spec.generate_anomaly_score2(test_signal)\n",
    "    index_changes = np.where(score > np.percentile(score, 99))[0]\n",
    "    cutoff = np.percentile(score, 99)\n",
    "    cutoff = 7 * np.mean(score)\n",
    "    pred_anom = []\n",
    "    for i in range(0, len(score)):\n",
    "        if score[i] > cutoff:\n",
    "            pred_anom.append(1)\n",
    "        else:\n",
    "            pred_anom.append(0)\n",
    "            \n",
    "    if \"Benchmark\" in file:\n",
    "        prec_list.append(precision_score(df.anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.anomaly.values, pred_anom) )\n",
    "    else:\n",
    "        prec_list.append(precision_score(df.is_anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.is_anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.is_anomaly.values, pred_anom) )\n",
    "\n",
    "np.mean(prec_list), np.mean(rec_list), np.mean(f1score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enhanced SR with averaging/filtering of saliency map\n",
    "# cutoff = 2.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "#def generate_anomaly_score(self, values, type=\"avg\"):\n",
    "#    extended_series = merge_series(values, self.series_window_size, self.series_window_size)\n",
    "#    mag = self.frequency_domain_map(extended_series)[: len(values)]\n",
    "#    ave_filter = Box_filter(mag, self.score_window_size)\n",
    "#    score = (mag - ave_filter) / ave_filter\n",
    "#    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.5968055594659185, 0.8690790440124405, 0.6590783629749551)"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec_list, rec_list, f1score_list = [], [], []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(os.path.join(path,file), header=0)\n",
    "    test_signal = df.value.values \n",
    "    score = spec.generate_anomaly_score(test_signal)\n",
    "    #index_changes = np.where(score > np.percentile(score, 99))[0]\n",
    "    cutoff = 2.8\n",
    "    pred_anom = []\n",
    "    for i in range(0, len(score)):\n",
    "        if score[i] > cutoff:\n",
    "            pred_anom.append(1)\n",
    "        else:\n",
    "            pred_anom.append(0)\n",
    "            \n",
    "    if \"Benchmark\" in file:\n",
    "        prec_list.append(precision_score(df.anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.anomaly.values, pred_anom) )\n",
    "    else:\n",
    "        prec_list.append(precision_score(df.is_anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.is_anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.is_anomaly.values, pred_anom) )\n",
    "\n",
    "np.mean(prec_list), np.mean(rec_list), np.mean(f1score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.6589798720628981, 0.8312036686714798, 0.6940316418644611)"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec_list, rec_list, f1score_list = [], [], []\n",
    "\n",
    "for file in files:\n",
    "    df1 = pd.read_csv(os.path.join(path,file), header=0)\n",
    "    df = df1.iloc[int(len(df1)/2):, :]\n",
    "    test_signal = df.value.values \n",
    "    score = spec.generate_anomaly_score(test_signal)\n",
    "    #index_changes = np.where(score > np.percentile(score, 99))[0]\n",
    "    cutoff = 2.8\n",
    "    pred_anom = []\n",
    "    for i in range(0, len(score)):\n",
    "        if score[i] > cutoff:\n",
    "            pred_anom.append(1)\n",
    "        else:\n",
    "            pred_anom.append(0)\n",
    "            \n",
    "    if \"Benchmark\" in file:\n",
    "        prec_list.append(precision_score(df.anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.anomaly.values, pred_anom) )\n",
    "    else:\n",
    "        prec_list.append(precision_score(df.is_anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.is_anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.is_anomaly.values, pred_anom) )\n",
    "\n",
    "np.mean(prec_list), np.mean(rec_list), np.mean(f1score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Half of the data [ TEST ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.784573328578778, 0.7552290545053432, 0.7320365590665248)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec_list, rec_list, f1score_list = [], [], []\n",
    "\n",
    "for file in files:\n",
    "    df1 = pd.read_csv(os.path.join(path,file), header=0)\n",
    "    df = df1.iloc[int(len(df1)/2): , : ]\n",
    "    test_signal = df.value.values \n",
    "    score = spec.generate_anomaly_score(test_signal)\n",
    "    index_changes = np.where(score > np.percentile(score, 99))[0]\n",
    "    cutoff = np.percentile(score, 99)\n",
    "    cutoff = 4\n",
    "    pred_anom = []\n",
    "    for i in range(0, len(score)):\n",
    "        if score[i] > cutoff:\n",
    "            pred_anom.append(1)\n",
    "        else:\n",
    "            pred_anom.append(0)\n",
    "            \n",
    "    if \"Benchmark\" in file:\n",
    "        prec_list.append(precision_score(df.anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.anomaly.values, pred_anom) )\n",
    "    else:\n",
    "        prec_list.append(precision_score(df.is_anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.is_anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.is_anomaly.values, pred_anom) )\n",
    "\n",
    "np.mean(prec_list), np.mean(rec_list), np.mean(f1score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  if __name__ == '__main__':\n",
      "/Users/manjunath.adinarayan/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:9: RuntimeWarning: invalid value encountered in long_scalars\n",
      "  if __name__ == '__main__':\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.21379291921598106, 0.9024549278672852, 0.3206594749799114)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prec_list, rec_list, f1score_list = [], [], []\n",
    "\n",
    "for file in files:\n",
    "    df = pd.read_csv(os.path.join(path,file), header=0)\n",
    "\n",
    "    test_signal = df.value.values\n",
    "\n",
    "    score = spec.generate_anomaly_score(test_signal)\n",
    "\n",
    "    index_changes = np.where(score > np.percentile(score, 98))[0]\n",
    "\n",
    "    cutoff = np.percentile(score, 98)\n",
    "\n",
    "    pred_anom = []\n",
    "    for i in range(0, len(score)):\n",
    "        if score[i] > cutoff:\n",
    "            pred_anom.append(1)\n",
    "        else:\n",
    "            pred_anom.append(0)\n",
    "\n",
    "    if \"Benchmark\" in file:\n",
    "        prec_list.append(precision_score(df.anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.anomaly.values, pred_anom) )\n",
    "    else:\n",
    "        prec_list.append(precision_score(df.is_anomaly.values, pred_anom) )\n",
    "        rec_list.append(recall_score(df.is_anomaly.values, pred_anom) )\n",
    "        f1score_list.append(f1_score(df.is_anomaly.values, pred_anom) )\n",
    "\n",
    "np.mean(prec_list), np.mean(rec_list), np.mean(f1score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "367"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "for file in files:\n",
    "    if \"Benchmark\" in file:\n",
    "        cnt = cnt + 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
